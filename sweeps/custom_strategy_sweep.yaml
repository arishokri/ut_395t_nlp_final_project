# Sweep configuration for filtering strategies
# Experiments with cartography filtering and cluster filtering on training set
# (cluster filtering does not filter validation set to avoid cluster mismatch)

program: run.py
method: bayes # Intelligent search that learns from results
project: qa-cartography-experiments
name: custom-strategy

# Metric to optimize
# Using F1 instead of exact_match because:
# - F1 is more lenient and rewards partial matches, providing better training signal
# - Exact match is very strict (single char difference = wrong), can be noisy for model selection
# - F1 correlates well with EM; both metrics are logged to W&B for comparison
metric:
  name: eval/f1
  goal: maximize

# Fixed parameters for all runs
parameters:
  # Model and dataset
  model:
    value: google/electra-small-discriminator
  dataset:
    value: Eladio/emrqa-msquad
  max_length:
    value: 512

  # Dataset size limits (set to null for full dataset)
  max_train_samples:
    value: 5000 # null = use full training set
  max_eval_samples:
    value: 2000 # null = use full validation set

  # Training configuration
  num_train_epochs:
    value: 3
  per_device_train_batch_size:
    value: 96

  # Cartography and filtering
  enable_cartography:
    value: false

  # Apply filtering to validation set (only applies when filter_ambiguous=true)
  filter_validation:
    value: true

  ### Filteration Techniques
  # Rule Based
  filter_rule_based:
    values: [true, false]

  rule_sim_threshold:
    distribution: uniform
    min: 0.05
    max: 0.15

  # Cluster Based
  filter_clusters:
    values: [true, false]

  exclude_noise_cluster:
    values: [true, false]

  min_cluster_probability:
    distribution: uniform
    min: 0.65
    max: 0.90

  # Cartography Based
  filter_ambiguous:
    values: [true, false]

  train_variability_margin:
    distribution: uniform
    min: 0.13
    max: 0.24

  ambiguous_top_fraction:
    distribution: uniform
    min: 0.30
    max: 0.40
  ### Label Smoothing and Soft Weighting
  use_label_smoothing:
    values: [true, false]
  
  use_soft_weighting:
    values: [true, false]

# Drop percentage threshold - terminate early if too much data is dropped
max_drop_percentage:
  value: 60 # Fail if more than 30% of data is dropped (filtered out)

early_terminate:
  type: hyperband
  min_iter: 1
  eta: 3
  # s: 2
