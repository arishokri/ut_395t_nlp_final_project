{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from dataset_cartography import (\n",
    "    analyze_cartography_by_question_type,\n",
    "    categorize_examples,\n",
    "    get_examples_by_category,\n",
    "    load_cartography_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Load Cartography Metrics\n",
    "\n",
    "First, load the cartography metrics generated during training.\n",
    "Make sure you've run training with `--enable_cartography` first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cartography metrics\n",
    "cartography_df = load_cartography_metrics(\"../cartography_output_full\")\n",
    "\n",
    "print(f\"Loaded metrics for {len(cartography_df)} examples\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "cartography_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Categorize Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize examples based on confidence and variability\n",
    "cartography_df = categorize_examples(cartography_df)\n",
    "\n",
    "# Show distribution\n",
    "print(\"Category Distribution:\")\n",
    "print(cartography_df['category'].value_counts())\n",
    "print(\"\\nPercentages:\")\n",
    "print(cartography_df['category'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Visualize the Data Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot colored by category\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = {\n",
    "    'easy': 'green',\n",
    "    'hard': 'red',\n",
    "    'ambiguous': 'orange',\n",
    "    'easy_variable': 'lightgreen'\n",
    "}\n",
    "\n",
    "for category in cartography_df['category'].unique():\n",
    "    data = cartography_df[cartography_df['category'] == category]\n",
    "    ax.scatter(\n",
    "        data['variability'],\n",
    "        data['confidence'],\n",
    "        c=colors.get(category, 'gray'),\n",
    "        label=category,\n",
    "        alpha=0.6,\n",
    "        s=30\n",
    "    )\n",
    "\n",
    "# Add median lines\n",
    "ax.axhline(cartography_df['confidence'].median(), color='black', \n",
    "           linestyle='--', alpha=0.5, label='Median confidence')\n",
    "ax.axvline(cartography_df['variability'].median(), color='black', \n",
    "           linestyle='--', alpha=0.5, label='Median variability')\n",
    "\n",
    "ax.set_xlabel('Variability', fontsize=14)\n",
    "ax.set_ylabel('Confidence', fontsize=14)\n",
    "ax.set_title('Dataset Cartography Map', fontsize=16, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Get Example Samples from Each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "dataset = load_dataset(\"Eladio/emrqa-msquad\")\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "## taken from helpers.py\n",
    "if \"id\" not in train_df.columns:\n",
    "    print(\"Generating IDs for dataset examples...\")\n",
    "    from helpers import generate_hash_ids\n",
    "    \n",
    "    # Generate IDs and add as a new column\n",
    "    train_df['id'] = train_df.apply(lambda row: generate_hash_ids(row)['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 hardest examples\n",
    "hard_ids = get_examples_by_category(cartography_df, 'hard', n=5)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HARDEST EXAMPLES (Low confidence, low variability)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, ex_id in enumerate(hard_ids, 1):\n",
    "    example = train_df[train_df['id'] == ex_id].iloc[0]\n",
    "    metrics = cartography_df.loc[ex_id]\n",
    "    \n",
    "    print(f\"\\n{i}. Example ID: {ex_id}\")\n",
    "    print(f\"   Confidence: {metrics['confidence']:.3f} | Variability: {metrics['variability']:.3f} | Correctness: {metrics['correctness']:.3f}\")\n",
    "    print(f\"   Question: {example['question']}\")\n",
    "    print(f\"   Answer: {example['answers']['text'][0]}\")\n",
    "    print(f\"   Context snippet: {example['context'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 most ambiguous examples\n",
    "ambiguous_ids = get_examples_by_category(cartography_df, 'ambiguous', n=5)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MOST AMBIGUOUS EXAMPLES (Low confidence, high variability)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, ex_id in enumerate(ambiguous_ids, 1):\n",
    "    example = train_df[train_df['id'] == ex_id].iloc[0]\n",
    "    metrics = cartography_df.loc[ex_id]\n",
    "    \n",
    "    print(f\"\\n{i}. Example ID: {ex_id}\")\n",
    "    print(f\"   Confidence: {metrics['confidence']:.3f} | Variability: {metrics['variability']:.3f} | Correctness: {metrics['correctness']:.3f}\")\n",
    "    print(f\"   Question: {example['question']}\")\n",
    "    print(f\"   Answer: {example['answers']['text'][0]}\")\n",
    "    print(f\"   Context snippet: {example['context'][:200]}...\")\n",
    "    print(\"-\" * 80)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 easiest examples\n",
    "easy_ids = get_examples_by_category(cartography_df, 'easy', n=5)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EASIEST EXAMPLES (High confidence, low variability)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, ex_id in enumerate(easy_ids, 1):\n",
    "    example = train_df[train_df['id'] == ex_id].iloc[0]\n",
    "    metrics = cartography_df.loc[ex_id]\n",
    "    \n",
    "    print(f\"\\n{i}. Example ID: {ex_id}\")\n",
    "    print(f\"   Confidence: {metrics['confidence']:.3f} | Variability: {metrics['variability']:.3f} | Correctness: {metrics['correctness']:.3f}\")\n",
    "    print(f\"   Question: {example['question']}\")\n",
    "    print(f\"   Answer: {example['answers']['text'][0]}\")\n",
    "    print(f\"   Context snippet: {example['context'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 5. Analyze by Question Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cartography metrics by question type\n",
    "qtype_analysis = analyze_cartography_by_question_type(cartography_df, train_df)\n",
    "\n",
    "print(\"Cartography Metrics by Question Type:\")\n",
    "print(\"=\"*80)\n",
    "qtype_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize by question type\n",
    "# Merge to get question types\n",
    "merged = cartography_df.join(train_df.set_index('id')[['question']], how='inner')\n",
    "\n",
    "def classify_question(q):\n",
    "    q_low = q.lower()\n",
    "    if any(x in q_low for x in [\"when\", \"date\", \"time\", \"year\"]):\n",
    "        return \"temporal\"\n",
    "    elif any(x in q_low for x in [\"how many\", \"how much\", \"dose\", \"dosage\"]):\n",
    "        return \"numerical\"\n",
    "    elif any(x in q_low for x in [\"what\", \"which\"]):\n",
    "        return \"what/which\"\n",
    "    elif any(x in q_low for x in [\"has\", \"does\", \"is\", \"was\", \"did\"]):\n",
    "        return \"yes/no\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "merged['question_type'] = merged['question'].apply(classify_question)\n",
    "\n",
    "# Box plot by question type\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, metric in zip(axes, ['confidence', 'variability', 'correctness']):\n",
    "    data_by_type = [merged[merged['question_type'] == qt][metric].values \n",
    "                    for qt in merged['question_type'].unique()]\n",
    "    \n",
    "    ax.boxplot(data_by_type, tick_labels=merged['question_type'].unique())\n",
    "    ax.set_ylabel(metric.capitalize(), fontsize=12)\n",
    "    ax.set_title(f'{metric.capitalize()} by Question Type', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 6. Combine with Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation predictions (if you have them)\n",
    "try:\n",
    "    with open(\"../eval_baseline_emrqa/eval_predictions.jsonl\", \"r\") as f:\n",
    "        predictions = [json.loads(line) for line in f]\n",
    "    \n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    \n",
    "    # Add error indicator\n",
    "    pred_df['is_wrong'] = pred_df.apply(\n",
    "        lambda row: row['predicted_answer'] != row['answers']['text'][0],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Merge with cartography\n",
    "    combined = pred_df.merge(\n",
    "        cartography_df,\n",
    "        left_on='id',\n",
    "        right_index=True,\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Error rate by category\n",
    "    error_by_category = combined.groupby('category')['is_wrong'].agg(['mean', 'sum', 'count'])\n",
    "    error_by_category.columns = ['error_rate', 'num_errors', 'total']\n",
    "    \n",
    "    print(\"Error Analysis by Cartography Category:\")\n",
    "    print(\"=\"*80)\n",
    "    print(error_by_category)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    error_by_category['error_rate'].plot(kind='bar', ax=ax, color='crimson', alpha=0.7)\n",
    "    ax.set_ylabel('Error Rate', fontsize=12)\n",
    "    ax.set_xlabel('Category', fontsize=12)\n",
    "    ax.set_title('Error Rate by Cartography Category', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"No evaluation predictions found. Run evaluation first to see error analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 7. Filter Dataset Based on Cartography\n",
    "\n",
    "You can use cartography to create filtered training sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Remove ambiguous examples (potential label noise)\n",
    "clean_ids = cartography_df[cartography_df['category'] != 'ambiguous'].index.tolist()\n",
    "print(f\"Clean dataset (no ambiguous): {len(clean_ids)} examples\")\n",
    "\n",
    "# Strategy 2: Focus on hard examples for curriculum learning\n",
    "hard_ids = cartography_df[cartography_df['category'] == 'hard'].index.tolist()\n",
    "print(f\"Hard examples only: {len(hard_ids)} examples\")\n",
    "\n",
    "# Strategy 3: Balanced sampling\n",
    "n_per_category = 1000\n",
    "balanced_ids = []\n",
    "for cat in ['easy', 'hard', 'ambiguous']:\n",
    "    cat_ids = cartography_df[cartography_df['category'] == cat].index[:n_per_category].tolist()\n",
    "    balanced_ids.extend(cat_ids)\n",
    "\n",
    "print(f\"Balanced dataset: {len(balanced_ids)} examples\")\n",
    "\n",
    "# Save filtered IDs for future use\n",
    "with open('filtered_example_ids.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'clean': clean_ids,\n",
    "        'hard': hard_ids,\n",
    "        'balanced': balanced_ids\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved filtered IDs to filtered_example_ids.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall summary\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET CARTOGRAPHY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal examples analyzed: {len(cartography_df)}\")\n",
    "print(f\"\\nMetric ranges:\")\n",
    "print(f\"  Confidence:   {cartography_df['confidence'].min():.3f} - {cartography_df['confidence'].max():.3f} (mean: {cartography_df['confidence'].mean():.3f})\")\n",
    "print(f\"  Variability:  {cartography_df['variability'].min():.3f} - {cartography_df['variability'].max():.3f} (mean: {cartography_df['variability'].mean():.3f})\")\n",
    "print(f\"  Correctness:  {cartography_df['correctness'].min():.3f} - {cartography_df['correctness'].max():.3f} (mean: {cartography_df['correctness'].mean():.3f})\")\n",
    "\n",
    "print(\"\\nCategory distribution:\")\n",
    "for cat, count in cartography_df['category'].value_counts().items():\n",
    "    pct = 100 * count / len(cartography_df)\n",
    "    print(f\"  {cat:15s}: {count:6d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
