# Sweep configuration for label smoothing and soft weighting strategies
# Experiments with variability-based training modifications
# Evaluates on full validation set (no filtering)

program: run.py
method: bayes # Intelligent search that learns from results
project: qa-cartography-experiments
name: smooth${use_label_smoothing}-weight${use_soft_weighting}

# Metric to optimize
# Using F1 instead of exact_match because:
# - F1 is more lenient and rewards partial matches, providing better training signal
# - Exact match is very strict (single char difference = wrong), can be noisy for model selection
# - F1 correlates well with EM; both metrics are logged to W&B for comparison
metric:
  name: eval/f1
  goal: maximize

# Fixed parameters for all runs
parameters:
  # Model and dataset
  model:
    value: google/electra-small-discriminator
  dataset:
    value: Eladio/emrqa-msquad
  max_length:
    value: 512

  # Dataset size limits (set to null for full dataset)
  max_train_samples:
    value: 5000 # null = use full training set
  max_eval_samples:
    value: 1000 # null = use full validation set

  # Training configuration
  num_train_epochs:
    value: 3
  per_device_train_batch_size:
    value: 64

  # Enable cartography tracking (required for smoothing/weighting)
  enable_cartography:
    value: false

  # No filtering on training or validation
  filter_ambiguous:
    value: false
  filter_clusters:
    value: false
  filter_rule_based:
    value: false
  filter_validation:
    value: false

  # Grid search over smoothing and weighting strategies
  use_label_smoothing:
    values: [true, false]

  smoothing_factor:
    values: [0.2, 0.4, 0.6, 0.8]

  use_soft_weighting:
    values: [true, false]

  weight_clip_min:
    values: [0.05, 0.1, 0.2]

  weight_clip_max:
    values: [5.0, 10.0, 15.0]
